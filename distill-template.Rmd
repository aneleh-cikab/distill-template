---
title: "High resolution traffic accident prediction in Berlin"
description: |
  We trained several machine learning models to predict the risk of occurrence of a traffic accident on a road segment for a given hour and day in Berlin.
author: 
  - name: Ma. Adelle Gia Arbo 
    url: 216132@hertie-school.org
  - name: Helena Bakic
    url: bakic.helena@outlook.com
  - name: Benedikt Ströbl
    url: 213712@hertie-school.org
date: "`r Sys.Date()`" 
categories: 
  - Machine Learning 
creative_commons: CC BY
repository_url: https://github.com/benediktstroebl/Machine-Learning-Project-Group-F
output: 
  distill::distill_article: 
    self_contained: false
preview: figures/BERTfig3.png
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# Load dependencies 
library(reticulate) # For rendering Python code
library(kableExtra)
library(knitr)
```


## Problem

Traffic accidents are one of the leading causes of death and injuries globally, and in Germany they cause over 3,000 deaths and 300,000 injuries yearly. Studying traffic accidents and where and why they happen can help policy makers make our roads safer.

However, traffic accident prediction is not an easy task. There are at least two key issues to tackle. First decision to make is on the granularity, or spatial precision to which we predict accidents. One approach could be focusing only on a few select roads that are covered by sophisticated measurement instruments like loop detectors and cameras. This allows researchers to precisely measure important features such as traffic flow and lane occupancy. Another approach could be predicting accidents, or their severity, on datasets with millions of accidents aggregated at the level of the country. This approach helps uncover patterns that would be difficult to find on smaller datasets, but lacks precision that could help policy makers improve traffic safety at the level ofa  community or a city.

Second key issue with traffic accident prediction is a computational one. Although traffic accidents have serious consequences they remain, luckily, rare events. However, many machine learning models do not do well when predicting rare events -- in part due to the focus on minimisation of the overall error rather than the detection of the rare class. Fortunately, computational approaches and models that tackle imbalanced datasets do exist and seem to be successful in predicting rare events.

We wanted to build on previous work in two main ways. First, inspired by a recent paper [@hebert2019high] we applied a novel approach in traffic accident forecasting that aims to predicts the risk of an accident on a particular road segment withing a city road network at a particular day and hour. We believe that this approach is particularly useful for policy makers interested in road-safety improvement. Second, we explore and provide new evidence on the performance of different approaches for rare event prediction in the field of traffic accident forecasting.

## Data

We conducted this study using the example of accidents in Berlin using the following data sources:

* Records of traffic accidents in Berlin: [Open Data Berlin](https://daten.berlin.de/) shares records of all traffic accidents that happened between 2018 and 2020; a total of 38,851 occurrences. For this study we used data on GPS-coordinates, year, month, day of the week, and hour of the accident.

* Berlin road segment data: We used two datasets provided by the [Open Data Informationsstelle (Odis)](https://odis-berlin.de/ressourcen/): 
  + To match locations of traffic accidents (Figure 1a) to road segments in Berlin (Figure 1b) we used the existing [geometric information dataset]((https://daten.odis-berlin.de/de/dataset/detailnetz_strassenabschnitte/)) on road segments in Berlin. From here we also used data on the length of the road segment.
  + We used road segment surface [dataset](https://daten.odis-berlin.de/de/dataset/) to extract the information on whether a road segment is a main road or a side street.
  

```{r fig1, echo = FALSE, fig.show='hold', fig.align="center", fig.cap = "(a) Collision points (left), (b) Road Network (right)"}
knitr::include_graphics(c("figures/1a.png", "figures/1b.png"))
```


* Weather data: Using the [Wetterdienst API](https://wetterdienst.readthedocs.io/en/latest/
overview.html) we collected data on temperature (°C), humidity (%), precipitation duration (average minutes per 10 minutes intervals in the hour before the accident), precipitation height (average mm in the hour before the accident), and visibility (m) for every accident location, day of the week, and hour of the day between 2018 and 2020 from 5 Berlin weather stations.

* Sun elevation: We used the Python API [PySolar](https://pysolar.readthedocs.io/en/latest/) to collect data on sun elevation angles per date and location in Berlin.


## Method 

The workflow of this study can be seen in Figure 2.

```{r fig2, eval = TRUE, echo = FALSE, fig.align='center',fig.cap = "Study workflow"}
knitr::include_graphics("figures/workflow.png")
```

### Generation of negative cases

After we collected raw data, we we first generated negative cases, that is, events when accidents did not happen. In traffic accident forecasting only positive cases (that is, occurrence of the accidents) are recorded. This makes sense, particularly as most of such records come from a traffic authority responding to an accident. However, that also means that available datasets have no records of negative cases at all -- so they have to be generated. Luckily, having an accurate database of accidents (recorded by the Berlin police), means that we know when accidents did not happen -- and that is at all possible other locations and times that were not recorded as accidents! Of course, it is not feasible to analyse all cases where accidents did not happen, as that would be computationally difficult. What we did instead, following the usual approach, was to calculate all possible combinations of time and locations for negative events and then drew a sample from it. We tried different accident/non-accident rations, as we will describe later, but in the end the one that worked the best was 5 non-accidents for every accident.

### Data pre-processing

The major part of data pre-processing included matching the accident GPS-locations to existing road segments in Berlin. This was done by creating a spatial join function and specifying a buffer. The matching function finds which road segments intersect the collision point's circle area and match these segments to the collision point. Increasing (decreasing) the buffer value makes the circle area larger (smaller), thereby  increasing (decreasing) the number of road segments matched to a collision point. For example, setting the buffer to 2m (Figure 3a) identifies fewer road segments than setting the buffer to 20m (Figure 3b). A bigger buffer was also more correct in detecting accidents that occurred on road intersections. Different buffer values were used to make sure that we match all accident and non-accident GPS-locations to corresponding segments.  

```{r fig3, echo = FALSE, fig.show='hold', fig.align="center", fig.cap = "(a) Matching 2m buffer (left), (b) Matching 20m buffer (right)"}
knitr::include_graphics(c("figures/2_2.png", "figures/2_20.png"))
```

We then matched all other data to road segments' midpoints. For weather features, we used the data for the closest weather station, and if that data was missing, second closest. Since Berlin accident dataset does not report the exact day of the month when the accident happened, we computed the monthly average per hour and used that information instead. Time features were recoded cyclicaly using sine and cosine functions to account for the dact that the extreme values (e.g. hour 1 and 23) have a similar meaning. The features we included in the model were:

1. month_cos and month_sin: cosine and sine of cyclical encoded month
2. hour_cos and hour_sin: cosine and sine of cyclical encoded hour
3. weekday: day of the week (Monday = 1, Sunday = 7)
4. collision_cnt: number of accidents at a road segment in the previous year/s
5. length_m: lenght of a road segment in meters
6. side_strt: road segment is a side street (1) or a main road (0)
7. temperature (°C)
8. humidity (%)
9. visibility (m)
10. prec_height: average mm per 10 minutes intervals in the hour before event
11. prec_duration: average minutes per 10 minutes intervals in the hour before the event
12. sun_elevation_angle: solar elevation angle in °

We then split the dataset into training (years 2018 and 2019) and test (year 2020). The final training dataset had in total 52,118 road segments where accidents occurred and 260,702 where they didn't. Here's a snippet of the final dataset we were working with:

```{r kable}
df <- read.csv("data/full_sample.csv")
#head <- head(df)

kable(head(df), "html") %>%
    kable_styling() %>%
    scroll_box(width = "100%", height = "200px")
```

<br>

And here's what the variables' distributions look like:

```{r fig4, eval = TRUE, echo = FALSE, out.width = '100%', fig.align='center', fig.cap = "Histograms of features for the training dataset"}
knitr::include_graphics("figures/histograms.png")
```

Finally, we can already get a glimpse of whether or not some road segments are more dangerous than others. As we can see from the Figure 5 below, it does seem that some main, long road segments -- that lead around the city centre or in it -- are more dangerous than small, side road segments. But, to see how correct we are when we make this prediction, we need to develop prediction models. 

```{r fig5, eval = TRUE, echo = FALSE, fig.align='center',fig.cap = "Road segments with the highest (above) and lowest (below) number of accidents"}
knitr::include_graphics("figures/segments.png")
```


### Selected models

We implemented 7 machine learning models:

1. Logistic Regression (Logit)
2. Standard Random Forrest (SRF)
3. Balanced Random Forrest (BRF)
4. Standard Random Forrest with SMOTE and RUS (SRF_SMOTE_RUS)
5. Balanced Bagging (BB)
6. Support Vector Classifier with SMOTE and RUS (SCV_SMOTE_RUS)
7. Extreme Gradient Boosting (XGBoost)

The models we selected are widely used for various problems and also in prediction of rare events. However, a small note on SMOTE and RUS techniques will be made. SOMOTE and RUS are re-sampling techniques that have been found to work well for imbalanced datasets. A discussion of these techniques is beyond the scope of this article, but a detailed discussion can be found elsewhere [chawla2002smote]. For this study, we applied SMOTE and RUS using 30% over-sampling and 50% under-sampling. In this case that means that on a training dataset containing 300,000 observations with imbalance factor of 5 (250,000 negative:50,000 positive), we first re-sample the minority class to have 30% the number of the majority class (75,000), then use random under-sampling to reduce the number of examples in the majority class to have 50% more than the minority class (150,000).

### Hyperparameter tuning strategy

We used random- and grid- search with 5-fold cross validation to tune our hyperparameters. As a scoring metric we chose the Area Under the ROC curve. We parametrized our search space by different hyperparameters unique to each model architecture; for instance, in Random Forest models, the number of trees, maximum depth, and minimum samples required to be at a terminal node, among others, were optimized. Moreover, we parametrized the sampling strategies---the intended class imbalance factor after re-sampling---that is applied to re-sample the dataset for our model implementations that use SMOTE and RUS.

### Evaluation approach




**Footnotes and Sidenotes**

You can use footnotes ^[This is a footnote. You can view this by hovering over the footnote in text.] or sidenotes to elaborate on a concept throughout the paper. 

<aside>
This is a side note. 
</aside>


## Results 

Present your most important results. Tables containing many numbers are overwhelming. Be selective and choose just the results that convey the story you're telling. Make it clear what the evaluation metrics are and what's being compared.

## Analysis 

Show any plots, diagrams, examples and visualisations to provide interesting analysis. Make it clear what the reader should conclude from each figure.

## Conclusion(s)

Briefly draw some main conclusions from your work. If you wish, you can outline future work.
